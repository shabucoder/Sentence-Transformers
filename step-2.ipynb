{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi-task transformer Implementation\n",
    "\n",
    "To support multi-task learning, we modify the original Sentence Transformer architecture (which as done in step 1) by adding task-specific heads. Each head is responsible for handling a particular task. The main components include:\n",
    "\n",
    "- **Transformer Backbone**: Utilizes a pre-trained transformer model (e.g., DistilBERT) to generate sentence embeddings.\n",
    "  - **Task A Head**: A linear layer for sentence classification.\n",
    "  - **Task B Head**: A linear layer for sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabareeshvangadari/Fetch_Assignment/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name distilbert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model on device: mps\n",
      "Sentence 1: \"The new smartphone has an excellent camera.\"\n",
      "  Task A Prediction (Sentence Classification): Technology\n",
      "  Task B Prediction (Sentiment Analysis): Negative\n",
      "\n",
      "Sentence 2: \"I am disappointed with the service.\"\n",
      "  Task A Prediction (Sentence Classification): Technology\n",
      "  Task B Prediction (Sentiment Analysis): Negative\n",
      "\n",
      "Sentence 3: \"The weather today is sunny and bright.\"\n",
      "  Task A Prediction (Sentence Classification): Technology\n",
      "  Task B Prediction (Sentiment Analysis): Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# multi_task_sentence_transformer.py\n",
    "\n",
    "# multi_task_sentence_transformer.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class MultiTaskSentenceTransformer(nn.Module):\n",
    "    def __init__(self, transformer_model='distilbert-base-uncased', num_classes_task_a=3, num_classes_task_b=3, device=None):\n",
    "        \"\"\"\n",
    "        Initializes the multi-task sentence transformer model.\n",
    "\n",
    "        Args:\n",
    "            transformer_model (str): Name of the pre-trained transformer model.\n",
    "            num_classes_task_a (int): Number of classes for Task A (Sentence Classification).\n",
    "            num_classes_task_b (int): Number of classes for Task B (Sentiment Analysis).\n",
    "            device (torch.device, optional): The device to run the model on. Defaults to None, which auto-selects.\n",
    "        \"\"\"\n",
    "        super(MultiTaskSentenceTransformer, self).__init__()\n",
    "        \n",
    "        # Determine device\n",
    "        if device is None:\n",
    "            if torch.backends.mps.is_available():\n",
    "                self.device = torch.device(\"mps\")\n",
    "            elif torch.cuda.is_available():\n",
    "                self.device = torch.device(\"cuda\")\n",
    "            else:\n",
    "                self.device = torch.device(\"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        print(f\"Initializing model on device: {self.device}\")\n",
    "        \n",
    "        # Initialize the Sentence Transformer model on the specified device\n",
    "        self.transformer = SentenceTransformer(transformer_model, device=self.device)\n",
    "        \n",
    "        # Task A: Sentence Classification Head\n",
    "        self.classification_head = nn.Linear(self.transformer.get_sentence_embedding_dimension(), num_classes_task_a).to(self.device)\n",
    "        \n",
    "        # Task B: Sentiment Analysis Head\n",
    "        self.sentiment_head = nn.Linear(self.transformer.get_sentence_embedding_dimension(), num_classes_task_b).to(self.device)\n",
    "        \n",
    "        # Optionally freeze transformer parameters if not training\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        \"\"\"\n",
    "        Forward pass to obtain predictions for both tasks.\n",
    "\n",
    "        Args:\n",
    "            sentences (list of str): Input sentences.\n",
    "\n",
    "        Returns:\n",
    "            dict: Predictions for Task A and Task B.\n",
    "        \"\"\"\n",
    "        # Generate sentence embeddings\n",
    "        embeddings = self.transformer.encode(sentences, convert_to_tensor=True, device=self.device)\n",
    "        \n",
    "        # Task A Predictions\n",
    "        task_a_logits = self.classification_head(embeddings)\n",
    "        task_a_predictions = torch.argmax(task_a_logits, dim=1)\n",
    "        \n",
    "        # Task B Predictions\n",
    "        task_b_logits = self.sentiment_head(embeddings)\n",
    "        task_b_predictions = torch.argmax(task_b_logits, dim=1)\n",
    "        \n",
    "        return {\n",
    "            'Task_A_Predictions': task_a_predictions,\n",
    "            'Task_B_Predictions': task_b_predictions\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the multi-task model\n",
    "    model = MultiTaskSentenceTransformer()\n",
    "    \n",
    "    # Sample sentences for testing\n",
    "    sample_sentences = [\n",
    "        \"The new smartphone has an excellent camera.\",\n",
    "        \"I am disappointed with the service.\",\n",
    "        \"The weather today is sunny and bright.\"\n",
    "    ]\n",
    "    \n",
    "    # Perform forward pass\n",
    "    predictions = model(sample_sentences)\n",
    "    \n",
    "    # Define label mappings for demonstration\n",
    "    task_a_labels = {0: \"Technology\", 1: \"Service\", 2: \"Weather\"}\n",
    "    task_b_labels = {0: \"Negative\", 1: \"Positive\", 2: \"Neutral\"}\n",
    "    \n",
    "    # Display predictions\n",
    "    for idx, sentence in enumerate(sample_sentences):\n",
    "        task_a_pred = predictions['Task_A_Predictions'][idx].item()\n",
    "        task_b_pred = predictions['Task_B_Predictions'][idx].item()\n",
    "        print(f\"Sentence {idx+1}: \\\"{sentence}\\\"\")\n",
    "        print(f\"  Task A Prediction (Sentence Classification): {task_a_labels.get(task_a_pred, 'Unknown')}\")\n",
    "        print(f\"  Task B Prediction (Sentiment Analysis): {task_b_labels.get(task_b_pred, 'Unknown')}\\n\")\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
