{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentiment Transformer model \n",
    "\n",
    "model = SentenceTransformer('distilbert-base-uncased')\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentance 1                       :\"Apple releases the new iPhone this fall.\"\n",
      "Embeddings of first 6 dimensions: [-0.35644856 -0.07131387  0.40865803 -0.04822442  0.2467562  -0.19633032]....\n",
      "\n",
      "Sentance 2                       :\"The movie received excellent reviews from critics.\"\n",
      "Embeddings of first 6 dimensions: [ 0.333448   -0.22270063  0.00373817  0.11186788 -0.15513083  0.09906107]....\n",
      "\n",
      "Sentance 3                       :\"Climate change poses significant risks to biodiversity.\"\n",
      "Embeddings of first 6 dimensions: [ 0.16737251  0.24889603 -0.26863915  0.38667983  0.25752744 -0.44028884]....\n",
      "\n",
      "lenghth of Fixed Dimensions each sentence: 768\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Code Implementation for sentence Transformer \n",
    "\n",
    "def encode_sentences(sentences):\n",
    "    \"\"\"\n",
    "    Encodes a list of sentences into fixed-length embeddings.\n",
    "    Args:\n",
    "        sentences (list of str): Sentences to encode.\n",
    "    Returns:\n",
    "        torch.Tensor: Embeddings tensor.\n",
    "    \"\"\"\n",
    "    embedding = model.encode(sentences, convert_to_tensor=True)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "\n",
    "###  Testing with Sample Sentence\n",
    "\n",
    "sample_sentences = [\n",
    "        \"Apple releases the new iPhone this fall.\",\n",
    "        \"The movie received excellent reviews from critics.\",\n",
    "        \"Climate change poses significant risks to biodiversity.\"\n",
    "    ]\n",
    "    \n",
    "embeddings = encode_sentences(sample_sentences)\n",
    "\n",
    "for i, sentence in enumerate(sample_sentences):\n",
    "    print(f'Sentance {i+1}                       :\\\"{sentence}\\\"')\n",
    "    print(f'Embeddings of first 6 dimensions: {embeddings[i][:6].cpu().numpy()}....\\n')\n",
    "\n",
    "print(f'lenghth of Fixed Dimensions each sentence: {len(embeddings[0])}' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Only the first six dimensions of each high-dimensional embedding are displayed for clarity ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Architectural Choices Discussion\n",
    "\n",
    "#### **Transformer Backbone**\n",
    "\n",
    "- **Choice:** `distilbert-base-uncased` model Selected for its efficiency and lightweight nature compared to BERT, which speeds up training and inference.\n",
    "\n",
    "#### **Pooling Strategy**\n",
    "\n",
    "- **Choice:** Mean Pooling (default in `SentenceTransformer`)\n",
    "- **Reasoning:** Averages token embeddings to create a fixed-length sentence embedding, balancing simplicity and effectiveness in capturing semantic information.\n",
    "\n",
    "#### **Framework**\n",
    "\n",
    "- **Choice:** PyTorch which offers dynamic computation graphs and is widely supported in the NLP community, facilitating easy integration and customization.\n",
    "\n",
    "#### **Pre-trained Model Utilization**\n",
    "\n",
    "- **Choice:** Leveraged a pre-trained `distilbert-base-uncased` model\n",
    "- **Reasoning:** Utilizes transfer learning to benefit from extensive training on large datasets, reducing the need for extensive computational resources and training data.\n",
    "\n",
    "#### **Embedding Output Configuration**\n",
    "\n",
    "- **Choice:** Outputs embeddings as PyTorch tensors\n",
    "- **Reasoning:** Ensures compatibility with downstream tasks such as Named Entity Recognition (NER) or Sentiment Analysis, where tensor operations are essential.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
